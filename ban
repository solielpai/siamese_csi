from sklearn.utils import shuffle
from sklearn.base import BaseEstimator, RegressorMixin
from lg1 import train,test
import heapq
import lightgbm as lgb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from sklearn import preprocessing
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import Imputer


class PseudoLabeler(BaseEstimator, RegressorMixin):
    
    def __init__(self, model, test, features, target, sample_rate=0.5, seed=42):
        self.sample_rate = sample_rate
        self.seed = seed
        self.model = model
        self.model.seed = seed
        
        self.test = test
        self.features = features
        self.target = target
        
    def get_params(self, deep=True):
        return {
            "sample_rate": self.sample_rate,
            "seed": self.seed,
            "model": self.model,
            "test": self.test,
            "features": self.features,
            "target": self.target
        }

    def set_params(self, **parameters):
        for parameter, value in parameters.items():
            setattr(self, parameter, value)
        return self

        
    def fit(self, X, y):
        if self.sample_rate > 0.0:
            augemented_train = self.__create_augmented_train(X, y)
            self.model.fit(
                augemented_train[self.features],
                augemented_train[self.target]
            )
        else:
            self.model.fit(X, y)
        
        return self


    def __create_augmented_train(self, X, y):
        num_of_samples = int(len(test) * self.sample_rate)
        skf = StratifiedKFold(n_splits=5, random_state=20, shuffle=True)
        baseloss = []
        loss = 0
        t=10
        train=X.values
        lable=y.values
        for i, (train_index, test_index) in enumerate(skf.split(X, y)):
            
            print("Fold", i)
            self. model.fit(train[train_index], lable[train_index],
                          eval_names =['train','valid'],
                          eval_metric='auc',
                          eval_set=[(train[train_index], lable[train_index]), 
                                    (train[test_index], lable[test_index])],early_stopping_rounds=100)
            baseloss.append(self.model.best_score_['valid']['auc'])
            loss += self.model.best_score_['valid']['auc']
            train_p=self.model.predict_proba(train, num_iteration=self.model.best_iteration_)[:, 1]
            test_pred= self.model.predict_proba(test, num_iteration=self.model.best_iteration_)[:, 1]
    #predict_result['pred_prob']=predict_result['pred_prob']+train_p
            if loss<t:
                t=loss
                train_p=self.model.predict_proba(train, num_iteration=self.model.best_iteration_)[:, 1]
                test_pred= self.model.predict(test)
        #predict_result['pred_prob']  = train_p
            
            print('test mean:', test_pred.mean())
#            else:
#                pass
         #Train the model and creat the pseudo-labels
         
         
#        self.model.fit(X, y)
        pseudo_labels = test_pred
        a=heapq.nlargest(461, pseudo_labels)
        #np.savetxt(r'C:\Users\Administrator\Desktop\da\re.csv',pseudo_labels ,delimiter=',')
        #pseudo_labels.save_txt(r'C:\Users\Administrator\Desktop\da\re.csv')
        #self.model.predict(self.test[self.features])
#        threshold = 0.4 
        for i in range(len(pseudo_labels)):  
            pseudo_labels[i] = 1 if  pseudo_labels[i] in a else 0  
        np.savetxt(r'C:\Users\Administrator\Desktop\da\re.csv',pseudo_labels ,delimiter=',')
        #print(pseudo_labels,'adadasds')
#        
        # Add the pseudo-labels to the test set
        augmented_test = test.copy(deep=True)
        augmented_test[self.target] = pseudo_labels
        
        # Take a subset of the test set with pseudo-labels and append in onto
        # the training set
        sampled_test = augmented_test.sample(n=num_of_samples)
        temp_train = pd.concat([X, y], axis=1)
        augemented_train = pd.concat([sampled_test, temp_train])
        
        return augemented_train
        
    def predict(self, X):
        #self.model.predict(X).to_csv(r'C:\Users\Administrator\Desktop\da\re.csv'  , index=False)
        return self.model.predict(X)
    
    def get_model_name(self):
        return self.model.__class__.__name__

target = 'y'
test.drop(['y','cust_id'],axis=1,inplace=True)
features=test.columns
# Preprocess the data
X_train, X_test = train[features], test[features]
y_train = train[target]

# Create the PseudoLabeler with XGBRegressor as the base regressor
model = PseudoLabeler(
    lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.01, n_estimators=5000,
                           max_bin=425, subsample_for_bin=50000, objective='binary', min_split_gain=0,
                           min_child_weight=5, min_child_samples=10, subsample=0.8, subsample_freq=1,
                           colsample_bytree=1, reg_alpha=3, reg_lambda=5, seed=1000, n_jobs=10, silent=True),
    test,
    features,
    target
)
from sklearn.metrics import roc_auc_score
# Train the model and use it to predict
model.fit(X_train, y_train)
a=model.predict(X_test)
c=a.sum()
b=roc_auc_score(a,y_train)
