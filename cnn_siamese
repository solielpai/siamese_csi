import os
import glob
import time
import numpy as np
import tensorflow as tf
from skimage import io, transform
 
os.environ["TF_CPP_MIN_LOG_LEVEL"] = '3'
# 只显示 Error

pat='E:\CSI2'
w = 30
h = 30
c = 3
 
# 读取图片
def read_img(path, w, h):

    cate = [path+'\\'+ x for x in os.listdir(path) if os.path.isdir(path+'\\'+ x)]
    #print(cate)
 
    imgs = []
    labels = []
 
    #print('Start read the image ...')
 
    for index, folder in enumerate(cate):
        #print(index, folder)
        for im in glob.glob(folder + '/*.jpg'):
            #print('Reading The Image: %s' % im)
            img = io.imread(im)
            img = transform.resize(img, (w, h,3))
            imgs.append(img)
            labels.append(index)
 
    print('Finished ...')
 
    return np.asarray(imgs, np.float32), np.asarray(labels, np.float32)
data, label = read_img(path=pat, w=30, h=30)
#print(label) 

# 打乱顺序
def messUpOrder(data, label):
    num_example = data.shape[0]
    
    arr = np.arange(num_example)
    np.random.shuffle(arr)
    data = data[arr]
    label = label[arr]
    label=tf.one_hot(label,277, 1, 0)
    sess=tf.Session()
    sess.run(tf.global_variables_initializer())
    label=label.eval(session=sess)
    return data, label
data, label=messUpOrder(data, label)
# 
## 将所有数据分为训练集和验证集
def segmentation(data, label, ratio=0.8):
    num_example = data.shape[0]
    s = np.int(num_example * ratio)
    x_train = data[:s]
    y_train = label[:s] 
    x_val = data[s:]
    y_val = label[s:]
 
    return x_train, y_train, x_val, y_val
x_train, y_train, x_val, y_val=segmentation(data, label, ratio=0.8)

def we(shape):
    ini=tf.truncated_normal(shape,stddev=0.1)
    return tf.Variable(ini)
def bi(shape):
    ini=tf.constant(0.1,shape=shape)
    return tf.Variable(ini)
def conv2d(x,w):
    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')
def max_pool(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')
# 
# 
## 构建网络

    # 占位符
x = tf.placeholder(tf.float32, shape=[None, w, h, c], name='x')
y_ = tf.placeholder(tf.float32, shape=[None,277], name='y_')
 
    
w_1=we([3,3,3,32])
b_1=bi([32])
x_image=tf.reshape(x,[-1,30,30,3])
h_conv1=tf.nn.relu(conv2d(x_image,w_1)+b_1)
h_pool1=max_pool(h_conv1)
#第二个卷积层
w_2=we([3,3,32,64])
b_2=bi([64])
h_conv2=tf.nn.relu(conv2d(h_pool1,w_2)+b_2)
h_pool2=max_pool(h_conv2)
#全连接层
w_c1=we([8*8*64,1024])
b_c1=bi([1024])
x_1=tf.reshape(h_pool2,[-1,8*8*64])
h_f1=tf.nn.relu(tf.matmul(x_1,w_c1)+b_c1)

    #keep_prob=tf.placeholder('float')
h_d=tf.nn.dropout(h_f1,0.6)

#性能评估
w_c2=we([1024,277])
b_c2=bi([277])
logits=tf.nn.softmax(tf.matmul(h_d,w_c2)+b_c2)
print('logits')    
   
 
 
# 返回损失函数的值，准确值等参数
cross=-tf.reduce_sum(y_*tf.log(logits))
train_op=tf.train.AdamOptimizer(1e-4).minimize(cross)
correct=tf.equal(tf.argmax(y_,1),tf.argmax(logits,1))
acc=tf.reduce_mean(tf.cast(correct,'float'))

print(acc,'acc')

def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):
#    assert tf.shape(inputs) == len(targets)
    if shuffle:
        indices = np.arange(len(inputs))
        #print(len(inputs),inputs.shape,targets.shape,'输入len')
        np.random.shuffle(indices)
    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):
        #print(start_idx,'start_idx')
        if shuffle:
            excerpt = indices[start_idx:start_idx + batch_size]
            #print(excerpt.shape,'excerpt')
        else:
            excerpt = slice(start_idx, start_idx + batch_size)
          
       # print(excerpt.shape,'shape',excerpt,'excerpt')
        #print(inputs[excerpt].shape,targets[excerpt].shape,start_idx,'输出shape')
        yield( inputs[excerpt], targets[excerpt]) 
 
with tf.Session() as sess:
#sess.run(tf.initialize_all_variables())  
    sess.run(tf.initialize_all_variables()) 
    # 训练和测试数据，可将n_epoch设置更大一些
    n_epoch = 1000
    batch_size = 64

    #print('here is ok2') 
    for epoch in range(n_epoch):
        # training
        # ('here is ok1')
        train_loss, train_acc, n_batch = 0, 0, 0
        for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):
            #print(x_train_a.shape, y_train_a.shape,'here is ok')
            train_op.run(feed_dict={x: x_train_a, y_: y_train_a})

            ac=acc.eval(feed_dict={x: x_train_a, y_: y_train_a})
             #_,err, ac = sess.run([train_op, loss, acc], feed_dict={x: x_train_a, y_: y_train_a})
#            train_loss += err
            train_acc += ac
            n_batch += 1
        if epoch%10==0:
            print("train acc: %f" % (train_acc / n_batch))
    test_a=acc.eval(feed_dict={x: x_val, y_: y_val})
    print('test accuracy',test_a)      
    sess.close()
# 
# 

