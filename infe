import tensorflow as tf 
import matplotlib as plt
class siamese:

    # Create model
    def __init__(self):
        self.x1 = tf.placeholder(tf.float32, [None,2700])
        self.x2 = tf.placeholder(tf.float32, [None,2700])

        with tf.variable_scope("siames") as scope:
            self.o1 = self.network(self.x1)
            scope.reuse_variables()
            self.o2 = self.network(self.x2)
 
        # Create loss
        self.y_ = tf.placeholder(tf.float32, [None])
        self.t=None
        self.loss,self.losses,self.eud1 = self.loss_with_spring()
        print(self.loss)




    def network(self, x):
        #fc1 = self.fc_layer(x,1500, "fc1")
        # fc1=tf.layers.batch_normalization(fc1,training=True)
        # ac1 = tf.nn.relu(fc1)
        fc1 = self.fc_layer(x, 1024)
        fc1 = tf.layers.batch_normalization(fc1, training=True)
        ac1 = tf.nn.relu(fc1)
        fc2 = self.fc_layer(ac1, 1024)
        #fc2 = tf.layers.batch_normalization(fc2, training=True)
        ac2= tf.nn.relu(fc2)
        #tf.layers.batch_normalization(fc1)
        # fc3= self.fc_layer(ac2, 163, "fc2")
        # fc3=tf.layers.batch_normalization(fc3,training=True)
        # ac3 = tf.nn.relu(fc3)
        #fc3 = self.fc_layer(ac1, 64, "fc3")
        #ac2 = tf.nn.relu(fc3)
        fc3 = self.fc_layer(ac2, 50)
        fc3 = tf.nn.sigmoid(fc3)

        # 全连接层
       # %w_c1 = self.we([8 * 8 * 64, 1024])
       # b_c1 =self. bi([1024])

        return fc3

    def fc_layer(self, bottom, n_weight):
        assert len(bottom.get_shape()) == 2
        n_prev_weight = bottom.get_shape()[1]
        W= tf.truncated_normal(shape=[n_prev_weight, n_weight], stddev=0.01)
        b=tf.truncated_normal(shape=[ n_weight], stddev=0)
       # initer = tf.truncated_normal_initializer(stddev=0.01)
       # W = tf.get_variable(name + 'W',dtype=tf.float32, shape=[n_prev_weight, n_weight], initializer=initer)
       # b = tf.get_variable(name + 'b',dtype=tf.float32, initializer=tf.constant(0.01, shape=[n_weight], dtype=tf.float32))
        fc = tf.nn.bias_add(tf.matmul(bottom, W), b)
        return fc

    def loss_with_spring(self):
            print('loss,sdsjdsff')
            margin = 4.0
            labels_t = self.y_
            #        print(labels_t.shape(),'lsn')
            labels_f = tf.subtract(1.0, self.y_)  # labels_ = !labels;
            eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)

            eucd1 = tf.reduce_sum(eucd2, 1)
            eucd2 = tf.sqrt(eucd1)
            #eucd = tf.sqrt(eucd1 + 1e-6, name="eucd")
            C = tf.constant(margin)
            print(labels_t, eucd2, 'le')
            # yi*||CNN(p1i)-CNN(p2i)||^2 + (1-yi)*max(0, C-||CNN(p1i)-CNN(p2i)||^2)
            pos = tf.multiply(labels_t, eucd1)
            # neg = tf.mul(labels_f, tf.sub(0.0,eucd2), name="yi_x_eucd2")
            # neg = tf.mul(labels_f, tf.maximum(0.0, tf.sub(C,eucd2)), name="Nyi_x_C-eucd_xx_2")
            neg = tf.multiply(labels_f, tf.pow(tf.maximum(tf.subtract(C, eucd2), 0), 2))
            losses = tf.add(pos, neg)

            loss = tf.reduce_mean(losses)
            print(loss)
            return loss, losses, eucd1
#    def predict(self,loss):
#        loss=self.losses
#        print(loss.shape)
#        lo=loss[:,1]
#        l=loss[:,0]
#        a=tf.argmin(loss)
#        print(l[a])
#        return l[a]

    def we(self,shape):
        ini = tf.truncated_normal(shape, stddev=0.1)
        return tf.Variable(ini)

    def bi(self,shape):
        ini = tf.constant(0.1, shape=shape)
        return tf.Variable(ini)

    def conv2d(self,x, w):
        return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')

    def max_pool(self,x):
        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')


    def loss_with_step(self):
        margin = 4.0
        labels_t = self.y_
        labels_f = tf.subtract(1.0, self.y_, name="1-yi")          # labels_ = !labels;
        eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)
        eucd2 = tf.reduce_sum(eucd2, 1)
        eucd = tf.sqrt(eucd2+1e-6, name="eucd")
        C = tf.constant(margin, name="C")
        pos = tf.mul(labels_t, eucd, name="y_x_eucd")
        neg = tf.mul(labels_f, tf.maximum(0.0, tf.subtract(C, eucd)), name="Ny_C-eucd")
        losses = tf.add(pos, neg, name="losses")
        loss = tf.reduce_mean(losses, name="loss")
        return loss
